<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Introduction to local linear forests • grf</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><script src="../extra.js"></script><meta property="og:title" content="Introduction to local linear forests">
<meta property="og:description" content="grf">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body data-spy="scroll" data-target="#toc">
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">grf</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">1.2.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../articles/grf.html">Get started</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Tutorials
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/categorical_inputs.html">Categorical inputs</a>
    </li>
    <li>
      <a href="../articles/ci_and_num.trees.html">Confidence intervals and the number of trees</a>
    </li>
    <li>
      <a href="../articles/muhats.html">Estimating conditional means</a>
    </li>
    <li>
      <a href="../articles/diagnostics.html">Evaluating a causal forest fit</a>
    </li>
    <li>
      <a href="../articles/llf.html">Local linear forests</a>
    </li>
    <li>
      <a href="../articles/sample_weighting_examples.html">Sample weighting</a>
    </li>
    <li>
      <a href="../articles/visualize_tree.html">Visualize trees</a>
    </li>
  </ul>
</li>
<li>
  <a href="../REFERENCE.html">Algorithm reference</a>
</li>
<li>
  <a href="../DEVELOPING.html">Developing</a>
</li>
<li>
  <a href="../CHANGELOG.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/grf-labs/grf">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      

      </header><link href="llf_files/anchor-sections-1.0/anchor-sections.css" rel="stylesheet">
<script src="llf_files/anchor-sections-1.0/anchor-sections.js"></script><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1 data-toc-skip>Introduction to local linear forests</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/grf-labs/grf/blob/master/vignettes/llf.Rmd"><code>vignettes/llf.Rmd</code></a></small>
      <div class="hidden name"><code>llf.Rmd</code></div>

    </div>

    
    
<div class="sourceCode" id="cb1"><html><body><pre class="r"><span class="fu"><a href="https://rdrr.io/r/base/library.html">library</a></span>(<span class="no">grf</span>)
<span class="fu"><a href="https://rdrr.io/r/base/library.html">library</a></span>(<span class="no">glmnet</span>)
<span class="fu"><a href="https://rdrr.io/r/base/library.html">library</a></span>(<span class="no">ggplot2</span>)</pre></body></html></div>
<p>This document aims to show how to use local linear forests (LLF). We begin with the standard use case, walking through parameter choices and method details, and then discuss how to use local linear corrections with larger datasets.</p>
<div id="local-linear-forests-the-basics" class="section level2">
<h2 class="hasAnchor">
<a href="#local-linear-forests-the-basics" class="anchor"></a>Local Linear Forests: the basics</h2>
<p>Random forests are a popular and powerful nonparametric regression method, but can suffer in the presence of strong, smooth effects. Local linear regression is a great method for fitting relatively smooth functions in low dimensions, but quickly deteriorates due to the curse of dimensionality: it relies on Euclidean distance, which fast loses its locality even in 4 or 5 dimensions. This algorithm leverages the strengths of each method (the data adaptivity of random forests and smooth fits of local linear regression) to give improved predictions and confidence intervals. For a complete treatment of local linear forests (LLF), see <a href="https://arxiv.org/abs/1807.11408">our paper on ArXiv</a>.</p>
<p>Consider a random forest with <span class="math inline">\(B\)</span> trees predicting at a test point <span class="math inline">\(x_0\)</span>. In each tree <span class="math inline">\(b\)</span>, the test point falls into a leaf <span class="math inline">\(L_b(x_0)\)</span>. A regression forest predicts by averaging all responses in <span class="math inline">\(L_b(x_0)\)</span>, and then averaging those predictions <span class="math inline">\(\hat{\mu}_b(x_0)\)</span> over all trees. To gain a new perspective on random forests, we can swap the sum to start thinking about random forests as a kernel or weighting method in high dimensions.</p>
<p><span class="math display">\[\begin{align*}
\hat{\mu}(x_0) 
&amp;= \frac1B \sum_{b=1}^B \sum_{i=1}^n Y_i \frac{1\{x_i\in L_b(x_0)\}}{|L_b(x_0)|}\\
&amp;= \sum_{i=1}^n Y_i \frac1B \sum_{b=1}^B \frac{1\{x_i\in L_b(x_0)\}}{|L_b(x_0)|} \\
&amp;= \sum_{i=1}^n \alpha_i(x_0) Y_i,
\end{align*}\]</span> where the forest weight <span class="math inline">\(\alpha_i(x_0)\)</span> is the fraction of trees in which an observation appears in the same leaf as the target value of the covariate vector. <span class="math display">\[\begin{equation}
\alpha_i(x_0) = \frac1B \sum_{b=1}^B \frac{1\{x_i\in L_b(x_0)\}}{|L_b(x_0)|}
\end{equation}\]</span></p>
<p>Local linear forests take this one step further: now, instead of using the weights to fit a local average at <span class="math inline">\(x_0\)</span>, we use them to fit a local linear regression, with a ridge penalty for regularization. This amounts to solving the minimization problem below, with parameters: <span class="math inline">\(\mu(x)\)</span> for the local average, and <span class="math inline">\(\theta(x)\)</span> for the slope of the local line. <span class="math display">\[\begin{equation}
\begin{pmatrix} \hat{\mu}(x_0) \\ \hat{\theta}(x_0) \end{pmatrix} = \text{argmin}_{\mu,\theta} \left\{\sum_{i=1}^n \alpha_i(x_0) \left(Y_i - \mu(x_0) - (x_i - x_0)\theta(x_0) \right)^2 + \lambda ||\theta(x_0)||_2^2\right\}
\end{equation}\]</span></p>
<p>This enables us to (i) use local linear regression in high dimensions with a meaningful kernel, and (ii) predict with random forests even in the presence of smooth, strong signals.</p>
</div>
<div id="toy-example" class="section level2">
<h2 class="hasAnchor">
<a href="#toy-example" class="anchor"></a>Toy Example</h2>
<p>We start with a simple example illustrating when local linear forests can improve on random forests.</p>
<div class="sourceCode" id="cb2"><html><body><pre class="r"><span class="no">p</span> <span class="kw">&lt;-</span> <span class="fl">20</span>
<span class="no">n</span> <span class="kw">&lt;-</span> <span class="fl">1000</span>
<span class="no">sigma</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span>(<span class="fl">20</span>)

<span class="no">mu</span> <span class="kw">&lt;-</span> <span class="kw">function</span>(<span class="no">x</span>){ <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span>(<span class="fl">1</span> + <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span>(<span class="fl">6</span> * <span class="no">x</span>)) }
<span class="no">X</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span>(<span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span>(<span class="no">n</span> * <span class="no">p</span>, -<span class="fl">1</span>, <span class="fl">1</span>), <span class="kw">nrow</span> <span class="kw">=</span> <span class="no">n</span>)
<span class="no">Y</span> <span class="kw">&lt;-</span> <span class="fu">mu</span>(<span class="no">X</span>[,<span class="fl">1</span>]) + <span class="no">sigma</span> * <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span>(<span class="no">n</span>)

<span class="no">X.test</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span>(<span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span>(<span class="no">n</span> * <span class="no">p</span>, -<span class="fl">1</span>, <span class="fl">1</span>), <span class="kw">nrow</span> <span class="kw">=</span> <span class="no">n</span>)
<span class="no">ticks</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span>(-<span class="fl">1</span>, <span class="fl">1</span>, <span class="kw">length</span> <span class="kw">=</span> <span class="no">n</span>)
<span class="no">X.test</span>[,<span class="fl">1</span>] <span class="kw">&lt;-</span> <span class="no">ticks</span>
<span class="no">truth</span> <span class="kw">&lt;-</span> <span class="fu">mu</span>(<span class="no">ticks</span>)

<span class="no">forest</span> <span class="kw">&lt;-</span> <span class="fu"><a href="../reference/regression_forest.html">regression_forest</a></span>(<span class="no">X</span>, <span class="no">Y</span>)
<span class="no">preds.forest</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span>(<span class="no">forest</span>, <span class="no">X.test</span>)$<span class="no">predictions</span>

<span class="no">df</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span>(<span class="no">ticks</span>, <span class="no">truth</span>, <span class="no">preds.forest</span>))
<span class="no">g1</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span>(<span class="no">df</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span>(<span class="no">ticks</span>)) +
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span>(<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span>(<span class="kw">y</span> <span class="kw">=</span> <span class="no">preds.forest</span>, <span class="kw">color</span> <span class="kw">=</span> <span class="st">"Regression Forest"</span>), <span class="kw">show.legend</span> <span class="kw">=</span> <span class="no">F</span>, <span class="kw">size</span> <span class="kw">=</span> <span class="fl">0.6</span>) +
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span>(<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span>(<span class="kw">y</span> <span class="kw">=</span> <span class="no">truth</span>)) +
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">xlab</a></span>(<span class="st">"x"</span>) + <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ylab</a></span>(<span class="st">"y"</span>) + <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_bw</a></span>()
<span class="no">g1</span></pre></body></html></div>
<p><img src="llf_files/figure-html/unnamed-chunk-2-1.png" width="700"></p>
<div class="sourceCode" id="cb3"><html><body><pre class="r"><span class="no">ll.forest</span> <span class="kw">&lt;-</span> <span class="fu"><a href="../reference/ll_regression_forest.html">ll_regression_forest</a></span>(<span class="no">X</span>, <span class="no">Y</span>, <span class="kw">enable.ll.split</span> <span class="kw">=</span> <span class="fl">TRUE</span>)
<span class="no">preds.llf</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span>(<span class="no">ll.forest</span>, <span class="no">X.test</span>,
                     <span class="kw">linear.correction.variables</span> <span class="kw">=</span> <span class="fl">1</span>)$<span class="no">predictions</span>

<span class="no">df.llf</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span>(<span class="no">ticks</span>, <span class="no">truth</span>, <span class="no">preds.llf</span>))
<span class="no">g2</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span>(<span class="no">df.llf</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span>(<span class="no">ticks</span>)) +
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span>(<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span>(<span class="kw">y</span> <span class="kw">=</span> <span class="no">preds.llf</span>, <span class="kw">color</span> <span class="kw">=</span> <span class="st">"Local Linear Forest"</span>), <span class="kw">show.legend</span> <span class="kw">=</span> <span class="no">F</span>, <span class="kw">size</span> <span class="kw">=</span> <span class="fl">0.6</span>) +
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span>(<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span>(<span class="kw">y</span> <span class="kw">=</span> <span class="no">truth</span>)) +
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">xlab</a></span>(<span class="st">"x"</span>) + <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ylab</a></span>(<span class="st">"y"</span>) + <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_bw</a></span>()
<span class="no">g2</span></pre></body></html></div>
<p><img src="llf_files/figure-html/unnamed-chunk-3-1.png" width="700"></p>
</div>
<div id="parameters-for-llf-prediction" class="section level2">
<h2 class="hasAnchor">
<a href="#parameters-for-llf-prediction" class="anchor"></a>Parameters for LLF Prediction</h2>
<p>There are several modifications to discuss. We begin by listing out the subset of training parameters specific to local linear forests (users can also consider regression_forest tuning parameters, all of which apply here as well).</p>
<table class="table">
<caption>LLF Parameters.</caption>
<colgroup>
<col width="32%">
<col width="23%">
<col width="18%">
<col width="25%">
</colgroup>
<thead><tr class="header">
<th align="left">Parameters</th>
<th align="left">Value Options</th>
<th align="left">Default Value</th>
<th align="left">Details</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">Training Parameters</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">enable.ll.split</td>
<td align="left">TRUE/FALSE</td>
<td align="left">FALSE</td>
<td align="left">Optional choice to make forest splits based on ridge residuals as opposed to standard CART splits.</td>
</tr>
<tr class="odd">
<td align="left">ll.split.weight.penalty</td>
<td align="left">TRUE/FALSE</td>
<td align="left">FALSE</td>
<td align="left">If using local linear splits, user can specify whether to standaridze the ridge penalty by covariance (TRUE), or penalize all covariates equally (FALSE).</td>
</tr>
<tr class="even">
<td align="left">ll.split.lambda</td>
<td align="left">Non-negative double</td>
<td align="left">0.1</td>
<td align="left">Ridge penalty for splitting.</td>
</tr>
<tr class="odd">
<td align="left">ll.split.variables</td>
<td align="left">Vector of covariate indexes</td>
<td align="left">1:p</td>
<td align="left">Variables to use in split regressions.</td>
</tr>
<tr class="even">
<td align="left">ll.split.cutoff</td>
<td align="left">Integer between 0 and n.</td>
<td align="left">Square root of n.</td>
<td align="left">If greater than 0, when leaves reach this size, forest uses regression coefficients from the full dataset for ridge regressions during tree training. If equal to 0, trees run a regression in each leaf.</td>
</tr>
<tr class="odd">
<td align="left">Prediction parameters</td>
<td align="left"></td>
<td align="left"></td>
<td align="left"></td>
</tr>
<tr class="even">
<td align="left">ll.lambda</td>
<td align="left">Non-negative double</td>
<td align="left">Tuned by default.</td>
<td align="left">Ridge penalty for prediction.</td>
</tr>
<tr class="odd">
<td align="left">ll.weight.penalty</td>
<td align="left">TRUE/FALSE</td>
<td align="left">FALSE</td>
<td align="left">Standardize ridge penalty by covariance (TRUE), or penalize all covariates equally (FALSE).</td>
</tr>
<tr class="even">
<td align="left">linear.correction.variables</td>
<td align="left">Vector of covariate indexes</td>
<td align="left">1:p</td>
<td align="left">Subset of indexes for variables to be used in local linear prediction.</td>
</tr>
</tbody>
</table>
</div>
<div id="training-the-algorithm" class="section level2">
<h2 class="hasAnchor">
<a href="#training-the-algorithm" class="anchor"></a>Training the Algorithm</h2>
<div class="sourceCode" id="cb4"><html><body><pre class="r"><span class="no">n</span> <span class="kw">&lt;-</span> <span class="fl">600</span>
<span class="no">p</span> <span class="kw">&lt;-</span> <span class="fl">20</span>
<span class="no">sigma</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span>(<span class="fl">20</span>)

<span class="no">mu</span> <span class="kw">&lt;-</span> <span class="kw">function</span>( <span class="no">x</span> ) {
  <span class="fl">10</span> * <span class="fu"><a href="https://rdrr.io/r/base/Trig.html">sin</a></span>(<span class="no">pi</span> * <span class="no">x</span>[<span class="fl">1</span>] * <span class="no">x</span>[<span class="fl">2</span>]) + <span class="fl">20</span> * ((<span class="no">x</span>[<span class="fl">3</span>] - <span class="fl">0.5</span>) ** <span class="fl">2</span>) + <span class="fl">10</span> * <span class="no">x</span>[<span class="fl">4</span>] + <span class="fl">5</span> * <span class="no">x</span>[<span class="fl">5</span>]
}

<span class="no">X</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span>(<span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span>(<span class="no">n</span> * <span class="no">p</span>, <span class="fl">0</span>, <span class="fl">1</span>), <span class="kw">nrow</span> <span class="kw">=</span> <span class="no">n</span>)
<span class="no">Y</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span>(<span class="no">X</span>, <span class="kw">FUN</span> <span class="kw">=</span> <span class="no">mu</span>, <span class="kw">MARGIN</span> <span class="kw">=</span> <span class="fl">1</span>) + <span class="no">sigma</span> * <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span>(<span class="no">n</span>)

<span class="no">X.test</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span>(<span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span>(<span class="no">n</span> * <span class="no">p</span>, <span class="fl">0</span>, <span class="fl">1</span>), <span class="kw">nrow</span> <span class="kw">=</span> <span class="no">n</span>)
<span class="no">truth</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span>(<span class="no">X.test</span>, <span class="kw">FUN</span> <span class="kw">=</span> <span class="no">mu</span>, <span class="kw">MARGIN</span> <span class="kw">=</span> <span class="fl">1</span>)

<span class="co"># regression forest predictions</span>
<span class="no">rforest</span> <span class="kw">&lt;-</span> <span class="fu"><a href="../reference/regression_forest.html">regression_forest</a></span>(<span class="no">X</span>, <span class="no">Y</span>, <span class="kw">honesty</span> <span class="kw">=</span> <span class="fl">TRUE</span>)
<span class="no">results</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span>(<span class="no">rforest</span>, <span class="no">X.test</span>)
<span class="no">preds</span> <span class="kw">&lt;-</span> <span class="no">results</span>$<span class="no">predictions</span>
<span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span>((<span class="no">preds</span> - <span class="no">truth</span>)**<span class="fl">2</span>)
<span class="co">#&gt; [1] 8.638002</span></pre></body></html></div>
<p>We can get LLF predictions both from a standard regression forest by specifying linear correction variables, or from a ll_regression_forest object. The parameter linear correction variables gives the variables to use for the final local regression step. This can simply be all variables, or might be a subset.</p>
<div class="sourceCode" id="cb5"><html><body><pre class="r"><span class="co"># llf predictions from regression_forest</span>
<span class="no">results.llf</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span>(<span class="no">rforest</span>, <span class="no">X.test</span>, <span class="kw">linear.correction.variables</span> <span class="kw">=</span> <span class="fl">1</span>:<span class="no">p</span>)
<span class="no">preds.llf</span> <span class="kw">&lt;-</span> <span class="no">results.llf</span>$<span class="no">predictions</span>
<span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span>((<span class="no">preds.llf</span> - <span class="no">truth</span>)**<span class="fl">2</span>)
<span class="co">#&gt; [1] 5.744372</span>

<span class="co"># llf predictions from ll_regression_forest</span>
<span class="no">forest</span> <span class="kw">&lt;-</span> <span class="fu"><a href="../reference/ll_regression_forest.html">ll_regression_forest</a></span>(<span class="no">X</span>, <span class="no">Y</span>, <span class="kw">honesty</span> <span class="kw">=</span> <span class="fl">TRUE</span>)
<span class="no">results.llf</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span>(<span class="no">forest</span>, <span class="no">X.test</span>)
<span class="no">preds.llf</span> <span class="kw">&lt;-</span> <span class="no">results.llf</span>$<span class="no">predictions</span>
<span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span>((<span class="no">preds.llf</span> - <span class="no">truth</span>)**<span class="fl">2</span>)
<span class="co">#&gt; [1] 5.752372</span></pre></body></html></div>
<div id="weight-penalties" class="section level3">
<h3 class="hasAnchor">
<a href="#weight-penalties" class="anchor"></a>Weight Penalties</h3>
<p>When we perform LLF predictions, we can either do a standard ridge regression (ll.weight.penalty set to FALSE), or scale by the covariance matrix (ll.weight.penalty set to TRUE): <span class="math inline">\(\hat{\beta}_\text{TRUE} = (X'AX (1 + \lambda))^{-1} X'AY\)</span>. This defaults to FALSE.</p>
<div class="sourceCode" id="cb6"><html><body><pre class="r"><span class="no">results.llf.unweighted</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span>(<span class="no">forest</span>, <span class="no">X.test</span>,
                               <span class="kw">ll.weight.penalty</span> <span class="kw">=</span> <span class="fl">FALSE</span>)
<span class="no">preds.llf.unweighted</span> <span class="kw">&lt;-</span> <span class="no">results.llf.unweighted</span>$<span class="no">predictions</span>
<span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span>((<span class="no">preds.llf.unweighted</span> - <span class="no">truth</span>)**<span class="fl">2</span>)
<span class="co">#&gt; [1] 5.752372</span>

<span class="no">results.llf.weighted</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span>(<span class="no">forest</span>, <span class="no">X.test</span>,
                               <span class="kw">ll.weight.penalty</span> <span class="kw">=</span> <span class="fl">TRUE</span>)
<span class="no">preds.llf.weighted</span> <span class="kw">&lt;-</span> <span class="no">results.llf.weighted</span>$<span class="no">predictions</span>
<span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span>((<span class="no">preds.llf.weighted</span> - <span class="no">truth</span>)**<span class="fl">2</span>)
<span class="co">#&gt; [1] 5.708388</span></pre></body></html></div>
</div>
<div id="residual-splits" class="section level3">
<h3 class="hasAnchor">
<a href="#residual-splits" class="anchor"></a>Residual Splits</h3>
<p>We also consider the role of tree training in local linear forests. A standard CART split minimizes prediction error from predicting leaf-wide averages. Instead, we can use residual splits, which minimize the corresponding prediction errors on ridge regression residuals. We might expect this to help in cases where there are strong linear signals from some covariates; we won’t waste any forest splits modelling those, but can still discover them in the final regression step. Essentially this helps us make the most efficient possible splits in the forest, knowing that we have a local regression coming up to predict. This is currently an experimental feature.</p>
<div class="sourceCode" id="cb7"><html><body><pre class="r"><span class="no">forest</span> <span class="kw">&lt;-</span> <span class="fu"><a href="../reference/ll_regression_forest.html">ll_regression_forest</a></span>(<span class="no">X</span>, <span class="no">Y</span>)
<span class="no">preds.cart.splits</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span>(<span class="no">forest</span>, <span class="no">X.test</span>)

<span class="no">ll.forest</span> <span class="kw">&lt;-</span> <span class="fu"><a href="../reference/ll_regression_forest.html">ll_regression_forest</a></span>(<span class="no">X</span>, <span class="no">Y</span>, <span class="kw">enable.ll.split</span> <span class="kw">=</span> <span class="fl">TRUE</span>,
                                  <span class="kw">ll.split.weight.penalty</span> <span class="kw">=</span> <span class="fl">TRUE</span>)
<span class="no">preds.ll.splits</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span>(<span class="no">ll.forest</span>, <span class="no">X.test</span>)

<span class="no">mse.cart.splits</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span>((<span class="no">preds.cart.splits</span>$<span class="no">predictions</span> - <span class="no">truth</span>)^<span class="fl">2</span>)
<span class="no">mse.ll.splits</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span>((<span class="no">preds.ll.splits</span>$<span class="no">predictions</span> - <span class="no">truth</span>)^<span class="fl">2</span>)

<span class="no">mse.cart.splits</span>
<span class="co">#&gt; [1] 5.81383</span>
<span class="no">mse.ll.splits</span>
<span class="co">#&gt; [1] 4.734676</span></pre></body></html></div>
<p>To uncover exactly why this works, we can look at plots showing the split frequencies of both forests. In each plot, tiles represent how many splits at at given level (y-axis) of the tree were at each feature (x-axis).</p>
<div class="sourceCode" id="cb8"><html><body><pre class="r"><span class="no">p</span> <span class="kw">&lt;-</span> <span class="fl">5</span>
<span class="no">XX</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span>(<span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span>(<span class="no">n</span> * <span class="no">p</span>, <span class="fl">0</span> ,<span class="fl">1</span>), <span class="kw">nrow</span> <span class="kw">=</span> <span class="no">n</span>)
<span class="no">YY</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span>(<span class="no">XX</span>, <span class="kw">MARGIN</span> <span class="kw">=</span> <span class="fl">1</span>, <span class="kw">FUN</span> <span class="kw">=</span> <span class="no">mu</span>) + <span class="no">sigma</span> * <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span>(<span class="no">n</span>)

<span class="no">forest2</span> <span class="kw">&lt;-</span> <span class="fu"><a href="../reference/regression_forest.html">regression_forest</a></span>(<span class="no">XX</span>, <span class="no">YY</span>)

<span class="no">max.depth</span> <span class="kw">&lt;-</span> <span class="fl">4</span>
<span class="no">freqs</span> <span class="kw">&lt;-</span> <span class="fu"><a href="../reference/split_frequencies.html">split_frequencies</a></span>(<span class="no">forest2</span>, <span class="kw">max.depth</span> <span class="kw">=</span> <span class="no">max.depth</span>)
<span class="no">d</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span>(<span class="no">freqs</span>)
<span class="no">dm</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span>(<span class="kw">variable</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sort.html">sort</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span>(<span class="no">d</span>), <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span>(<span class="no">d</span>))),
                 <span class="kw">value</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/vector.html">as.vector</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span>(<span class="no">d</span>)),
                 <span class="kw">depth</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span>(<span class="fl">1</span>:<span class="no">max.depth</span>, <span class="no">p</span>))

<span class="co"># normalize value by sum of value at depth</span>
<span class="kw">for</span>(<span class="no">i</span> <span class="kw">in</span> <span class="fl">1</span>:<span class="no">max.depth</span>){
  <span class="no">tot.depth</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span>(<span class="no">dm</span>[<span class="no">dm</span>$<span class="no">depth</span> <span class="kw">==</span> <span class="no">i</span>,]$<span class="no">value</span>)
  <span class="no">dm</span>[<span class="no">dm</span>$<span class="no">depth</span> <span class="kw">==</span> <span class="no">i</span>,]$<span class="no">value</span> <span class="kw">&lt;-</span> <span class="no">dm</span>[<span class="no">dm</span>$<span class="no">depth</span> <span class="kw">==</span> <span class="no">i</span>,]$<span class="no">value</span> / <span class="no">tot.depth</span>
}

<span class="no">g</span><span class="kw">&lt;-</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span>(<span class="no">dm</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span>(<span class="kw">x</span> <span class="kw">=</span> <span class="no">variable</span>, <span class="kw">y</span> <span class="kw">=</span> -<span class="no">depth</span>, <span class="kw">fill</span> <span class="kw">=</span> <span class="no">value</span>)) +
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_tile.html">geom_tile</a></span>() +
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">xlab</a></span>(<span class="st">"Variable"</span>) +
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ylab</a></span>(<span class="st">"Depth"</span>) +
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_gradient.html">scale_fill_gradient</a></span>(<span class="kw">low</span> <span class="kw">=</span> <span class="st">"white"</span>, <span class="kw">high</span> <span class="kw">=</span> <span class="st">"blue"</span>,<span class="kw">limits</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="fl">0</span>,<span class="fl">1</span>), <span class="st">"Frequency \n"</span>) +
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ggtitle</a></span>(<span class="st">""</span>) +
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span>(<span class="kw">text</span> <span class="kw">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html">element_text</a></span>(<span class="kw">size</span> <span class="kw">=</span> <span class="fl">15</span>))
<span class="no">g</span></pre></body></html></div>
<p><img src="llf_files/figure-html/unnamed-chunk-8-1.png" width="700"></p>
<div class="sourceCode" id="cb9"><html><body><pre class="r"><span class="no">ll.forest2</span> <span class="kw">&lt;-</span> <span class="fu"><a href="../reference/ll_regression_forest.html">ll_regression_forest</a></span>(<span class="no">XX</span>, <span class="no">YY</span>, <span class="kw">enable.ll.split</span> <span class="kw">=</span> <span class="fl">TRUE</span>,
                              <span class="kw">ll.split.weight.penalty</span> <span class="kw">=</span> <span class="fl">TRUE</span>)

<span class="no">freqs</span> <span class="kw">&lt;-</span> <span class="fu"><a href="../reference/split_frequencies.html">split_frequencies</a></span>(<span class="no">ll.forest2</span>, <span class="kw">max.depth</span> <span class="kw">=</span> <span class="no">max.depth</span>)
<span class="no">d</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span>(<span class="no">freqs</span>)
<span class="no">dm</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span>(<span class="kw">variable</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sort.html">sort</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/names.html">names</a></span>(<span class="no">d</span>), <span class="fu"><a href="https://rdrr.io/r/base/nrow.html">nrow</a></span>(<span class="no">d</span>))),
                 <span class="kw">value</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/vector.html">as.vector</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/matrix.html">as.matrix</a></span>(<span class="no">d</span>)),
                 <span class="kw">depth</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span>(<span class="fl">1</span>:<span class="no">max.depth</span>, <span class="no">p</span>))

<span class="kw">for</span>(<span class="no">i</span> <span class="kw">in</span> <span class="fl">1</span>:<span class="no">max.depth</span>){
  <span class="no">tot.depth</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span>(<span class="no">dm</span>[<span class="no">dm</span>$<span class="no">depth</span> <span class="kw">==</span> <span class="no">i</span>,]$<span class="no">value</span>)
  <span class="no">dm</span>[<span class="no">dm</span>$<span class="no">depth</span> <span class="kw">==</span> <span class="no">i</span>,]$<span class="no">value</span> <span class="kw">&lt;-</span> <span class="no">dm</span>[<span class="no">dm</span>$<span class="no">depth</span> <span class="kw">==</span> <span class="no">i</span>,]$<span class="no">value</span> / <span class="no">tot.depth</span>
}

<span class="no">g2</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span>(<span class="no">dm</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span>(<span class="kw">x</span><span class="kw">=</span><span class="no">variable</span>, <span class="kw">y</span><span class="kw">=</span>-<span class="no">depth</span>, <span class="kw">fill</span> <span class="kw">=</span> <span class="no">value</span>)) +
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_tile.html">geom_tile</a></span>() +
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">xlab</a></span>(<span class="st">"Variable"</span>) +
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ylab</a></span>(<span class="st">"Depth"</span>) +
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_gradient.html">scale_fill_gradient</a></span>(<span class="kw">low</span> <span class="kw">=</span> <span class="st">"white"</span>, <span class="kw">high</span> <span class="kw">=</span> <span class="st">"blue"</span>, <span class="kw">limits</span> <span class="kw">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span>(<span class="fl">0</span>,<span class="fl">1</span>), <span class="st">"Frequency \n"</span>) +
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ggtitle</a></span>(<span class="st">"Split Frequencies: LLF"</span>) +
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/theme.html">theme</a></span>(<span class="kw">text</span> <span class="kw">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/element.html">element_text</a></span>(<span class="kw">size</span> <span class="kw">=</span> <span class="fl">15</span>))
<span class="no">g2</span></pre></body></html></div>
<p><img src="llf_files/figure-html/unnamed-chunk-9-1.png" width="700"></p>
</div>
</div>
<div id="llf-prediction" class="section level2">
<h2 class="hasAnchor">
<a href="#llf-prediction" class="anchor"></a>LLF Prediction</h2>
<div id="ridge-parameter-selection" class="section level3">
<h3 class="hasAnchor">
<a href="#ridge-parameter-selection" class="anchor"></a>Ridge parameter selection</h3>
<p>The user can choose to specify a ridge regression parameter ll.lambda. When this variable is not set by the user, it will be selected by automatic parameter tuning. In general, we recommend letting the forest tune this parameter, or performing your own cross-validation loop. The exception to this would be for very large datasets.</p>
<div class="sourceCode" id="cb10"><html><body><pre class="r"><span class="no">results.llf.lambda</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span>(<span class="no">forest</span>, <span class="no">X.test</span>,
                             <span class="kw">ll.lambda</span> <span class="kw">=</span> <span class="fl">0.1</span>)
<span class="no">preds.llf.lambda</span> <span class="kw">&lt;-</span> <span class="no">results.llf.lambda</span>$<span class="no">predictions</span>
<span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span>((<span class="no">preds.llf.lambda</span> - <span class="no">truth</span>)**<span class="fl">2</span>)
<span class="co">#&gt; [1] 5.81383</span>

<span class="no">results.llf.lambda</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span>(<span class="no">forest</span>, <span class="no">X.test</span>) <span class="co"># automatic tuning  </span>
<span class="no">preds.llf.lambda</span> <span class="kw">&lt;-</span> <span class="no">results.llf.lambda</span>$<span class="no">predictions</span>
<span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span>((<span class="no">preds.llf.lambda</span> - <span class="no">truth</span>)**<span class="fl">2</span>)
<span class="co">#&gt; [1] 5.81383</span></pre></body></html></div>
</div>
<div id="linear-correction-variable-selection" class="section level3">
<h3 class="hasAnchor">
<a href="#linear-correction-variable-selection" class="anchor"></a>Linear Correction Variable Selection</h3>
<p>Especially with many covariates, it is reasonable to restrict the local regression to only include a few features of interest. We recommend using the lasso.</p>
<div class="sourceCode" id="cb11"><html><body><pre class="r"><span class="co"># Train forest</span>
<span class="no">forest</span> <span class="kw">&lt;-</span> <span class="fu"><a href="../reference/ll_regression_forest.html">ll_regression_forest</a></span>(<span class="no">X</span>, <span class="no">Y</span>)

<span class="co"># Select covariates </span>
<span class="no">lasso.mod</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/glmnet/man/cv.glmnet.html">cv.glmnet</a></span>(<span class="no">X</span>, <span class="no">Y</span>, <span class="kw">alpha</span> <span class="kw">=</span> <span class="fl">1</span>)
<span class="no">lasso.coef</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span>(<span class="no">lasso.mod</span>, <span class="kw">type</span> <span class="kw">=</span> <span class="st">"nonzero"</span>)
<span class="no">selected</span> <span class="kw">&lt;-</span> <span class="no">lasso.coef</span>[,<span class="fl">1</span>]
<span class="no">selected</span>
<span class="co">#&gt; [1] 1 2 4 5</span>

<span class="co"># Predict with all covariates</span>
<span class="no">llf.all.preds</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span>(<span class="no">forest</span>, <span class="no">X.test</span>)
<span class="no">results.all</span> <span class="kw">&lt;-</span> <span class="no">llf.all.preds</span>$<span class="no">predictions</span>
<span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span>((<span class="no">results.all</span> - <span class="no">truth</span>)**<span class="fl">2</span>)
<span class="co">#&gt; [1] 5.782246</span>

<span class="co"># Predict with just those covariates</span>
<span class="no">llf.lasso.preds</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span>(<span class="no">forest</span>, <span class="no">X.test</span>,
                           <span class="kw">linear.correction.variables</span> <span class="kw">=</span> <span class="no">selected</span>)
<span class="no">results.llf.lasso</span> <span class="kw">&lt;-</span> <span class="no">llf.lasso.preds</span>$<span class="no">predictions</span>
<span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span>((<span class="no">results.llf.lasso</span> - <span class="no">truth</span>)**<span class="fl">2</span>)
<span class="co">#&gt; [1] 4.7916</span></pre></body></html></div>
</div>
</div>
<div id="pointwise-confidence-intervals" class="section level2">
<h2 class="hasAnchor">
<a href="#pointwise-confidence-intervals" class="anchor"></a>Pointwise Confidence Intervals</h2>
<p>Last, consider variance estimates and confidence intervals, which are analogous to grf variance estimates. We use our first data-generating process for easier visualization.</p>
<div class="sourceCode" id="cb12"><html><body><pre class="r"><span class="no">mu</span> <span class="kw">&lt;-</span> <span class="kw">function</span>(<span class="no">x</span>){ <span class="fu"><a href="https://rdrr.io/r/base/Log.html">log</a></span>(<span class="fl">1</span> + <span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span>(<span class="fl">6</span> * <span class="no">x</span>)) }
<span class="no">p</span> <span class="kw">&lt;-</span> <span class="fl">20</span>

<span class="no">X</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span>(<span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span>(<span class="no">n</span> * <span class="no">p</span>, -<span class="fl">1</span>, <span class="fl">1</span>), <span class="kw">nrow</span> <span class="kw">=</span> <span class="no">n</span>)
<span class="no">Y</span> <span class="kw">&lt;-</span> <span class="fu">mu</span>(<span class="no">X</span>[,<span class="fl">1</span>]) + <span class="no">sigma</span> * <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span>(<span class="no">n</span>)

<span class="no">X.test</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span>(<span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span>(<span class="no">n</span> * <span class="no">p</span>, -<span class="fl">1</span>, <span class="fl">1</span>), <span class="kw">nrow</span> <span class="kw">=</span> <span class="no">n</span>)
<span class="no">ticks</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span>(-<span class="fl">1</span>, <span class="fl">1</span>, <span class="kw">length</span> <span class="kw">=</span> <span class="no">n</span>)
<span class="no">X.test</span>[,<span class="fl">1</span>] <span class="kw">&lt;-</span> <span class="no">ticks</span>
<span class="no">truth</span> <span class="kw">&lt;-</span> <span class="fu">mu</span>(<span class="no">ticks</span>)

<span class="co"># Select covariates </span>
<span class="no">lasso.mod</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/glmnet/man/cv.glmnet.html">cv.glmnet</a></span>(<span class="no">X</span>, <span class="no">Y</span>, <span class="kw">alpha</span> <span class="kw">=</span> <span class="fl">1</span>)
<span class="no">lasso.coef</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span>(<span class="no">lasso.mod</span>, <span class="kw">type</span> <span class="kw">=</span> <span class="st">"nonzero"</span>)
<span class="no">selected</span> <span class="kw">&lt;-</span> <span class="no">lasso.coef</span>[,<span class="fl">1</span>]
<span class="no">selected</span>
<span class="co">#&gt; [1] 1</span>

<span class="no">ll.forest</span> <span class="kw">&lt;-</span> <span class="fu"><a href="../reference/ll_regression_forest.html">ll_regression_forest</a></span>(<span class="no">X</span>, <span class="no">Y</span>, <span class="kw">enable.ll.split</span> <span class="kw">=</span> <span class="fl">TRUE</span>)
<span class="no">results.llf.var</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span>(<span class="no">ll.forest</span>, <span class="no">X.test</span>,
                           <span class="kw">linear.correction.variables</span> <span class="kw">=</span> <span class="no">selected</span>,
                           <span class="kw">estimate.variance</span> <span class="kw">=</span> <span class="fl">TRUE</span>)
<span class="no">preds.llf.var</span> <span class="kw">&lt;-</span> <span class="no">results.llf.var</span>$<span class="no">predictions</span>
<span class="no">variance.estimates</span> <span class="kw">&lt;-</span> <span class="no">results.llf.var</span>$<span class="no">variance.estimates</span>

<span class="co"># find lower and upper bounds for 95% intervals </span>
<span class="no">lower.llf</span> <span class="kw">&lt;-</span> <span class="no">preds.llf.var</span> - <span class="fl">1.96</span>*<span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span>(<span class="no">variance.estimates</span>)
<span class="no">upper.llf</span> <span class="kw">&lt;-</span> <span class="no">preds.llf.var</span> + <span class="fl">1.96</span>*<span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span>(<span class="no">variance.estimates</span>)

<span class="no">df</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span>(<span class="no">ticks</span>, <span class="no">truth</span>, <span class="no">preds.llf.var</span>, <span class="no">lower.llf</span>, <span class="no">upper.llf</span>))
<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span>(<span class="no">df</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span>(<span class="no">ticks</span>)) +
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span>(<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span>(<span class="kw">y</span> <span class="kw">=</span> <span class="no">preds.llf.var</span>, <span class="kw">color</span> <span class="kw">=</span> <span class="st">"Local Linear Forest"</span>), <span class="kw">show.legend</span> <span class="kw">=</span> <span class="no">F</span>, <span class="kw">size</span> <span class="kw">=</span> <span class="fl">0.6</span>) +
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span>(<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span>(<span class="kw">y</span> <span class="kw">=</span> <span class="no">truth</span>)) +
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span>(<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span>(<span class="kw">y</span> <span class="kw">=</span> <span class="no">lower.llf</span>), <span class="kw">color</span> <span class="kw">=</span> <span class="st">"gray"</span>, <span class="kw">lty</span> <span class="kw">=</span> <span class="fl">2</span>) +
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_path.html">geom_line</a></span>(<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span>(<span class="kw">y</span> <span class="kw">=</span> <span class="no">upper.llf</span>), <span class="kw">color</span> <span class="kw">=</span> <span class="st">"gray"</span>, <span class="kw">lty</span> <span class="kw">=</span> <span class="fl">2</span>) +
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">xlab</a></span>(<span class="st">"x"</span>) + <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ylab</a></span>(<span class="st">"y"</span>) + <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_bw</a></span>()</pre></body></html></div>
<p><img src="llf_files/figure-html/unnamed-chunk-12-1.png" width="700"></p>
</div>
<div id="a-note-on-larger-datasets" class="section level2">
<h2 class="hasAnchor">
<a href="#a-note-on-larger-datasets" class="anchor"></a>A Note on Larger Datasets</h2>
<p>Although generally local linear forests are an improvement over regular random forests, when the number of dimensions is very high, training and predicting using them can take long time. This is because with n_train and n_test train and test points, we are running n_test regressions with n_train data points each. However, sometimes we still want to use random forests and correct for linear trends. In this case (datasets with roughly 100,000 or more observations, although always context-dependent), selecting a small number linear correction variables is especially important. The current ridge parameter tuning will also take prohibitively long, and so we recommend either setting the value to 0.01 consistently, tuning this on a subset of the data, restricting the range of values considered, or cross-validating using a small number of shallow trees.</p>
<table class="table">
<caption>LLF Parameters and their function with large datasets.</caption>
<colgroup>
<col width="31%">
<col width="22%">
<col width="17%">
<col width="27%">
</colgroup>
<thead><tr class="header">
<th align="left">Parameters</th>
<th align="left">Value Options</th>
<th align="left">Default Value</th>
<th>Performance as n,p increase</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">Training Parameters</td>
<td align="left"></td>
<td align="left"></td>
<td></td>
</tr>
<tr class="even">
<td align="left">enable.ll.split</td>
<td align="left">TRUE/FALSE</td>
<td align="left">FALSE</td>
<td>For large n and p, ridge regressions in each leaf will take an especially long time. We therefore recommend either not using this feature, or setting the tuning parameters discussed below carefully. Please also note that this is still an experimental feature.</td>
</tr>
<tr class="odd">
<td align="left">ll.split.weight.penalty</td>
<td align="left">TRUE/FALSE</td>
<td align="left">FALSE</td>
<td>Unaffected</td>
</tr>
<tr class="even">
<td align="left">ll.split.lambda</td>
<td align="left">Non-negative double</td>
<td align="left">0.1</td>
<td>Unaffected</td>
</tr>
<tr class="odd">
<td align="left">ll.split.variables</td>
<td align="left">Vector of covariate indexes</td>
<td align="left">1:p</td>
<td>For large p (over 50), we recommend either limiting ll.split.variables to a subset, using CART splits, or enforcing a reasonably large split cutoff (below).</td>
</tr>
<tr class="even">
<td align="left">ll.split.cutoff</td>
<td align="left">Integer between 0 and n.</td>
<td align="left">Square root of n.</td>
<td>Increasing this parameter can help to speed up LL splits, and is recommended for users who want to use LL splits when training forests with large data.</td>
</tr>
<tr class="odd">
<td align="left">Prediction parameters</td>
<td align="left"></td>
<td align="left"></td>
<td></td>
</tr>
<tr class="even">
<td align="left">ll.lambda</td>
<td align="left">Non-negative double</td>
<td align="left">Tuned by default.</td>
<td>Tuning by default takes a long time with large datasets, and we recommend either writing your own, shorter cross-validation loop, or setting ll.lambda to a default value around 0.1 instead of using automatic tuning.</td>
</tr>
<tr class="odd">
<td align="left">ll.weight.penalty</td>
<td align="left">TRUE/FALSE</td>
<td align="left">FALSE</td>
<td>Unaffected</td>
</tr>
<tr class="even">
<td align="left">linear.correction.variables</td>
<td align="left">Vector of covariate indexes</td>
<td align="left">1:p</td>
<td>Limiting linear correction variables is a crucial step for efficient predictions as n, p increase. We highly recommend using a lasso, stepwise regression, prior knowledge, etc. to select a fairly small number of linear correction variables for LLF prediction in this case.</td>
</tr>
</tbody>
</table>
<p>The following code is set to not run currently; users can expect it to take approximately 5-6 minutes. LLF predictions with all p variables will be very slow, as will automatic tuning with this scale of data. However, we can still use linear corrections, just with more careful parameters. Users can increase the number of trees for better performance from both methods.</p>
<div class="sourceCode" id="cb13"><html><body><pre class="r"><span class="co"># generate data </span>
<span class="no">n</span> <span class="kw">&lt;-</span> <span class="fl">5e5</span>
<span class="no">p</span> <span class="kw">&lt;-</span> <span class="fl">20</span>

<span class="no">sigma</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span>(<span class="fl">20</span>)

<span class="no">f</span> <span class="kw">&lt;-</span> <span class="kw">function</span>(<span class="no">x</span>){
  <span class="fl">10</span> * <span class="fu"><a href="https://rdrr.io/r/base/Trig.html">sin</a></span>(<span class="no">pi</span> * <span class="no">x</span>[<span class="fl">1</span>] * <span class="no">x</span>[<span class="fl">2</span>]) + <span class="fl">10</span> * (<span class="no">x</span>[<span class="fl">3</span>] - <span class="fl">0.5</span>)**<span class="fl">2</span> + <span class="fl">10</span> * <span class="no">x</span>[<span class="fl">4</span>] + <span class="fl">5</span> * <span class="no">x</span>[<span class="fl">5</span>]
}

<span class="no">X</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span>(<span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span>(<span class="no">n</span> * <span class="no">p</span>, <span class="fl">0</span>, <span class="fl">1</span>), <span class="kw">nrow</span> <span class="kw">=</span> <span class="no">n</span>, <span class="kw">ncol</span> <span class="kw">=</span> <span class="no">p</span>)
<span class="no">Y</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span>(<span class="no">X</span>, <span class="kw">MARGIN</span> <span class="kw">=</span> <span class="fl">1</span>, <span class="kw">FUN</span> <span class="kw">=</span> <span class="no">f</span>) + <span class="no">sigma</span> * <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span>(<span class="no">n</span>)

<span class="no">X.test</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/matrix.html">matrix</a></span>(<span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span>(<span class="no">n</span> * <span class="no">p</span>, <span class="fl">0</span>, <span class="fl">1</span>), <span class="kw">nrow</span> <span class="kw">=</span> <span class="no">n</span>, <span class="kw">ncol</span> <span class="kw">=</span> <span class="no">p</span>)
<span class="no">truth.test</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/apply.html">apply</a></span>(<span class="no">X.test</span>, <span class="kw">MARGIN</span> <span class="kw">=</span> <span class="fl">1</span>, <span class="kw">FUN</span> <span class="kw">=</span> <span class="no">f</span>)

<span class="no">ptm</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/proc.time.html">proc.time</a></span>()
<span class="no">forest</span> <span class="kw">&lt;-</span><span class="fu"><a href="../reference/regression_forest.html">regression_forest</a></span>(<span class="no">X</span>, <span class="no">Y</span>, <span class="kw">tune.parameters</span> <span class="kw">=</span> <span class="st">"none"</span>, <span class="kw">num.trees</span> <span class="kw">=</span> <span class="fl">50</span>)
<span class="no">time.train</span> <span class="kw">&lt;-</span> (<span class="fu"><a href="https://rdrr.io/r/base/proc.time.html">proc.time</a></span>() - <span class="no">ptm</span>)<span class="kw">[[</span><span class="fl">3</span>]]

<span class="no">ptm</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/proc.time.html">proc.time</a></span>()
<span class="no">preds.grf</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span>(<span class="no">forest</span>, <span class="no">X.test</span>)$<span class="no">predictions</span>
<span class="no">mse.grf</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span>((<span class="no">preds.grf</span> - <span class="no">truth.test</span>)**<span class="fl">2</span>)
<span class="no">time.grf</span> <span class="kw">&lt;-</span> (<span class="fu"><a href="https://rdrr.io/r/base/proc.time.html">proc.time</a></span>() - <span class="no">ptm</span>)<span class="kw">[[</span><span class="fl">3</span>]]

<span class="no">ptm</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/proc.time.html">proc.time</a></span>()
<span class="no">ll.forest</span> <span class="kw">&lt;-</span> <span class="fu"><a href="../reference/ll_regression_forest.html">ll_regression_forest</a></span>(<span class="no">X</span>, <span class="no">Y</span>, <span class="kw">tune.parameters</span> <span class="kw">=</span> <span class="st">"none"</span>, <span class="kw">enable.ll.split</span> <span class="kw">=</span> <span class="fl">TRUE</span> ,<span class="kw">num.trees</span> <span class="kw">=</span> <span class="fl">50</span>)
<span class="no">time.train.ll</span> <span class="kw">&lt;-</span> (<span class="fu"><a href="https://rdrr.io/r/base/proc.time.html">proc.time</a></span>() - <span class="no">ptm</span>)<span class="kw">[[</span><span class="fl">3</span>]]

<span class="no">ptm</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/proc.time.html">proc.time</a></span>()
<span class="no">lasso.mod</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/glmnet/man/cv.glmnet.html">cv.glmnet</a></span>(<span class="no">X</span>, <span class="no">Y</span>, <span class="kw">alpha</span> <span class="kw">=</span> <span class="fl">1</span>)
<span class="no">lasso.coef</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span>(<span class="no">lasso.mod</span>, <span class="kw">type</span> <span class="kw">=</span> <span class="st">"nonzero"</span>)
<span class="no">selected</span> <span class="kw">&lt;-</span> <span class="no">lasso.coef</span>[,<span class="fl">1</span>]
<span class="no">selected</span>
<span class="no">time.lasso</span> <span class="kw">&lt;-</span> (<span class="fu"><a href="https://rdrr.io/r/base/proc.time.html">proc.time</a></span>() - <span class="no">ptm</span>)<span class="kw">[[</span><span class="fl">3</span>]]

<span class="no">ptm</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/proc.time.html">proc.time</a></span>()
<span class="no">preds.llf</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span>(<span class="no">ll.forest</span>, <span class="no">X.test</span>,
                    <span class="kw">linear.correction.variables</span> <span class="kw">=</span> <span class="no">selected</span>,
                    <span class="kw">ll.lambda</span> <span class="kw">=</span> <span class="fl">0.1</span>)$<span class="no">predictions</span>
<span class="no">mse.llf</span> <span class="kw">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span>((<span class="no">preds.llf</span> - <span class="no">truth.test</span>)**<span class="fl">2</span>)
<span class="no">time.llf</span> <span class="kw">&lt;-</span> (<span class="fu"><a href="https://rdrr.io/r/base/proc.time.html">proc.time</a></span>() - <span class="no">ptm</span>)<span class="kw">[[</span><span class="fl">3</span>]]

<span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span>(<span class="st">"GRF training took"</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span>(<span class="no">time.train</span>, <span class="fl">2</span>), <span class="st">"seconds. \n"</span>,
          <span class="st">"GRF predictions took"</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span>(<span class="no">time.train.ll</span>, <span class="fl">2</span>), <span class="st">"seconds. \n"</span>,
          <span class="st">"LLF training took"</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span>(<span class="no">time.grf</span>, <span class="fl">2</span>), <span class="st">"seconds. \n"</span>,
          <span class="st">"Lasso selection took"</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span>(<span class="no">time.lasso</span>, <span class="fl">2</span>), <span class="st">"seconds. \n"</span>,
          <span class="st">"LLF prediction took"</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span>(<span class="no">time.llf</span>, <span class="fl">2</span>), <span class="st">"seconds. \n"</span>,
          <span class="st">"LLF and lasso all in all took"</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span>(<span class="no">time.lasso</span> + <span class="no">time.llf</span>, <span class="fl">2</span>), <span class="st">"seconds. \n"</span>))

<span class="co"># GRF training took 342.14 seconds</span>
<span class="co"># LLF training took 215.64 seconds</span>
<span class="co"># GRF predictions took 20.25 seconds</span>
<span class="co"># Lasso selection took 15.10 seconds</span>
<span class="co"># LLF prediction took 45.40 seconds</span>
<span class="co"># LLF and lasso all in all took 60.50 seconds</span>

<span class="fu"><a href="https://rdrr.io/r/base/cat.html">cat</a></span>(<span class="fu"><a href="https://rdrr.io/r/base/paste.html">paste</a></span>(<span class="st">"GRF predictions had MSE"</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span>(<span class="no">mse.grf</span>, <span class="fl">2</span>), <span class="st">"\n"</span>,
          <span class="st">"LLF predictions had MSE"</span>, <span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span>(<span class="no">mse.llf</span>, <span class="fl">2</span>)))
<span class="co"># GRF predictions had MSE 0.81</span>
<span class="co"># LLF predictions had MSE 0.69</span></pre></body></html></div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">

        <nav id="toc" data-toggle="toc"><h2 data-toc-skip>Contents</h2>
    </nav>
</div>

</div>



      <footer><div class="copyright">
  <p>Developed by Julie Tibshirani, Susan Athey, Stefan Wager.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.5.1.</p>
</div>

      </footer>
</div>

  


  </body>
</html>
